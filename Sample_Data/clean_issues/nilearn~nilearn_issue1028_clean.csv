rectype,issueid,project_owner,project_name,actor,time,text,action,title,clean_text
rectype,issueid,project_owner,project_name,actor,time,text,action,title,text
issue_title,1028,nilearn,nilearn,mjboos,2016-02-27 12:14:58,"This is the encoding example for the Miyawaki et al., 2008 dataset, made at the Brainhack in Paris with @GaelVaroquaux 
",start issue,Encoding example,thi encod exampl miyawaki et al 2008 dataset made brainhack pari gaelvaroquaux
issue_closed,1028,nilearn,nilearn,GaelVaroquaux,2016-03-03 10:49:07,,closed issue,Encoding example,
pull_request_title,1028,nilearn,nilearn,mjboos,2016-02-27 12:14:58,"This is the encoding example for the Miyawaki et al., 2008 dataset, made at the Brainhack in Paris with @GaelVaroquaux 
",463dc2ab4d17fd7456b7677a1638237be075bc0e,Encoding example,thi encod exampl miyawaki et al 2008 dataset made brainhack pari gaelvaroquaux
pull_request_merged,1028,nilearn,nilearn,GaelVaroquaux,2016-03-03 10:49:07,Encoding example,2596a0d639b3863f098f87c75b5bbee9c3e25165,Pull request merge from mjboos/nilearn:encoding_example to nilearn/nilearn:master,encod exampl
issue_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:47:53,"Unless I missed a few more PEP8 errors, I think that I have made all my comments. So this is definitely almost there.

By the way: the current status of rendered doc can be seen on:
https://circle-artifacts.com/gh/nilearn/nilearn/1344/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/02_decoding/plot_miyawaki_encoding.html
",,,unless I miss pep8 error I think I made comment So definit almost By way current statu render doc seen
issue_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-03-02 21:51:44,"Looks great. I am +1 for merge.

Just to be sure that everything is right, I have restarted the CircleCI build after clearing the cache, as the downloaded dataset wasn't the latest.
",,,look great I 1 merg just sure everyth right I restart circleci build clear cach download dataset wasnt latest
issue_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-03-03 10:40:59,"@KamalakerDadi : I started the build again to try to refresh the cache. Indeed on CircleCI the rendering is wrong because of a caching problem, as it is still grabbing the broken brain mask.

Anyhow, I ran this on my computer and everything looks right.

Hence, I am +1 for merge.

There is one little thing, which is that the example runs for 10mn. We'd like to make this faster, as 10mn is quite a dent in our budget with regards to compute time for all the examples. I am playing a bit with the various estimators locally to see if I can make things faster.
",,,kamalakerdadi I start build tri refresh cach inde circleci render wrong cach problem still grab broken brain mask anyhow I ran comput everyth look right henc I 1 merg there one littl thing exampl run 10mn wed like make faster 10mn quit dent budget regard comput time exampl I play bit variou estim local see I make thing faster
issue_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-03-03 10:49:02,"OK, I remove my previous comment: the example is quite fast, the time was mostly due to the download time. So am merging this. Thank you very much @mjboos !
",,,OK I remov previou comment exampl quit fast time mostli due download time So merg thank much mjboo
issue_comment,1028,nilearn,nilearn,mjboos,2016-02-28 19:55:10,"Huh, there are still red backgrounds of the marked voxels in the rendered doc at: https://circle-artifacts.com/gh/nilearn/nilearn/1346/artifacts/0/home/ubuntu/nilearn/doc/_build/html/auto_examples/02_decoding/plot_miyawaki_encoding.html

But there shouldn't be, the scores of the marked voxels are >.45, and should be bright yellow for this colormap. I cannot reproduce this on my machine (or on another when I clone the repo), for me the voxels have the correct color for their score.

Any idea why it looks different with circle-ci?
",,,huh still red background mark voxel render doc but shouldnt score mark voxel ani idea look differ circleci
issue_comment,1028,nilearn,nilearn,KamalakerDadi,2016-03-03 09:05:42,"@GaelVaroquaux Have you started the build again ? What was wrong in last build ? I could not catch.
",,,gaelvaroquaux have start build what wrong last build I could catch
issue_comment,1028,nilearn,nilearn,KamalakerDadi,2016-03-03 10:46:22,"> Anyhow, I ran this on my computer and everything looks right.

Great. I have no other comments. Except that I think this example deserves place in Userguide module ?
",,,great I comment except I think exampl deserv place userguid modul
issue_comment,1028,nilearn,nilearn,KamalakerDadi,2016-03-03 10:50:00,"Great work @mjboos 
",,,great work mjboo
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:51:19,"In examples, we like to do the imports in the same ""cell"" as where we use the corresponding symbols: it makes it easier for beginner to relate the symbols to where they come from.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",In exampl like import cell use correspond symbol make easier beginn relat symbol come
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:51:54,""": the data after the first twelve files""
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(45, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",data first twelv file
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:52:44,"Maybe we could plot one or two image here, and have a text reminding us that these were the stimuli.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",mayb could plot one two imag text remind us stimuli
pull_request_commit_comment,1028,nilearn,nilearn,aabadie,2016-02-27 12:54:01,"MultiNiftiMas_k_er
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",multiniftimask
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:56:55,"Ah, maybe here is where we want to plot stimuli.

I would suggest moving the definition of y_shape here, to have things close to where they are understandable.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",Ah mayb want plot stimuli I would suggest move definit yshape thing close understand
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:57:54,"Can we not use scikit-learn's cross_val_score?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",can use scikitlearn crossvalscor
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:58:28,"Sorry, stupid comment. It cross_val_predict that we would need. But it's only in very recent scikit-learn versions.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",sorri stupid comment It crossvalpredict would need but recent scikitlearn version
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:58:50,"I wonder if, for Python beginners, a for loop wouldn't be easier to read.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",I wonder python beginn loop wouldnt easier read
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 12:59:44,"Well, no, actually, we should be able to combine that cell with the one after and use cross_val_score, no?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",well actual abl combin cell one use crossvalscor
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:00:15,"PEP8: you need a space after ','
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 need space
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:01:11,"We like to call the return of plot_stat_map 'display'. I think that it reflects better the type of object that this is. Tell me if you disagree, though.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",We like call return plotstatmap display I think reflect better type object tell disagre though
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:01:36,"Do we need the ""symmetric_cbar=False""
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",Do need symmetriccbarfals
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:02:51,"Can you modify index_to_xy_coord so that it's return argument can be passed to add_markers with any transformation. It will make the example simpler.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",can modifi indextoxycoord return argument pass addmark transform It make exampl simpler
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:03:16,"PEP8: space after ','
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 space
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:08:47,"Maybe you should say that this is partly reproducing the Miyawaki paper, from which the data comes from.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",mayb say partli reproduc miyawaki paper data come
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:09:45,"PEP8: space after coma

Also, any chance that you find a more explicit name for this variable?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 space coma also chanc find explicit name variabl
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-27 13:09:58,"PEP8: space after coma
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 space coma
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-27 22:01:29,"I think cross_val_score needs a scorer that returns a single float, but we need an array of scores (one for each voxel). We could do cross_val_score independently for each voxel and then concatenate, but that makes the example much slower (7 minutes vs. 20 seconds for me)
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",I think crossvalscor need scorer return singl float need array score one voxel We could crossvalscor independ voxel concaten make exampl much slower 7 minut vs 20 second
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:29:23,"In the examples, we tend to import modules in the cell where we need them, in order to have the imports as close as possible to the code that uses them.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",In exampl tend import modul cell need order import close possibl code use
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:31:06,"PEP8 tells us that there should not be spaces before and after the ""="" next to ""multioutput.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 tell us space next multioutput
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:33:17,"Maybe we can merge that cell with the next one, and have only one for loop. The ""predictions"" list might then not be needed.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",mayb merg cell next one one loop the predict list might need
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:33:43,"> I think cross_val_score needs a scorer that returns a single float, but
> we need an array of scores (one for each voxel). We could do
> cross_val_score independently for each voxel and then concatenate, but
> that makes the example much slower (7 minutes vs. 20 seconds for me)

Point taken.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",point taken
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:35:58,"We have a convention in nilearn to always end the names of the images with ""_img"". Would you mind changing  `score_map` to `score_img` and `thresholded_score_map` to `thresholded_score_img` ?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",We convent nilearn alway end name imag img would mind chang
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:36:51,"The 'show' should be only at the end of the file because in script mode it will block the execution of the script.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",the show end file script mode block execut script
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:38:19,"The red doesn't show, because the background is red. Maybe it's better to use cyan.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",the red doesnt show background red mayb better use cyan
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:42:35,"Maybe a line of comment on what is GridSpec.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",mayb line comment gridspec
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:43:24,"Maybe a title for the figure?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",mayb titl figur
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:45:35,"PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 say function call space equal sign use keywordargu unlik equal sign use assign outsid function call
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:45:51,"PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 say function call space equal sign use keywordargu unlik equal sign use assign outsid function call
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 16:46:03,"PEP8 says that, in function calls, there should be no spaces before and after equal signs used for keyword-arguments (unlike equal signs used in assignments, outside the function calls.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",pep8 say function call space equal sign use keywordargu unlik equal sign use assign outsid function call
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-28 17:58:10,"Cyan doesn't have a nice Sequential colormap like 'Reds' or 'Blues' (and the ones containing cyan just don't look good here), building one makes the tutorial more complicated. I've switched the red and blue marker, so the contrast to the surrounding voxels is stronger. I find it discriminative enough, but I can also add a custom colormap if you think that's better.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",cyan doesnt nice sequenti colormap like red blue one contain cyan dont look good build one make tutori complic ive switch red blue marker contrast surround voxel stronger I find discrimin enough I also add custom colormap think that better
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-28 18:08:44,"> I've switched the red and blue marker, so the contrast to the
> surrounding voxels is stronger. I find it discriminative enough,

That sounds good!
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",that sound good
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:30:26,"I wonder if that figure isn't too tall: the aspect ratio should probably be around 3/2. Right now, it has a lot of whitespace at the bottom.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",I wonder figur isnt tall aspect ratio probabl around 32 right lot whitespac bottom
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:33:21,"How about using cyan to be really robust to fluctuations in prediction power. (I am trying to understand why things vary across computers, but I haven't so far).
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",how use cyan realli robust fluctuat predict power I tri understand thing vari across comput I havent far
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:44:03,"Nitpick: this might be written:

```
cut_score = np.mean(scores, axis=0)
```
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",nitpick might written
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:45:42,"We tend to prefer using masker.inverse_transform. Is there a reason why it is not suitable here?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",We tend prefer use maskerinversetransform Is reason suitabl
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:49:19,"I am stupid: you told me why no cyan: no corresponding colormap. It's before coffee, sorry.

How about black, then? You can use the gray colormap.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",I stupid told cyan correspond colormap it coffe sorri how black you use gray colormap
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 08:52:40,"How about you add a 'vmax=.5' and see how it looks like on CircleCI. I suspect that outside the cuts there are some voxels that perform very well, and these are setting the max of the color range.

I've been staring at the code for a little while, and I still don't understand why it looks different on different computers :$.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",how add vmax5 see look like circleci I suspect outsid cut voxel perform well set max color rang ive stare code littl I still dont understand look differ differ comput
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:04:47,"perhaps ""based on information of presented stimuli""
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",perhap base inform present stimuli
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:06:43,"grammar
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",grammar
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:07:58,"binary (i.e., X and Y values) image
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",binari ie X Y valu imag
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:08:55,"point at the end of this sentence
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",point end sentenc
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:10:22,"perhaps use normal `#` instead
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(164, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",perhap use normal instead
pull_request_commit_comment,1028,nilearn,nilearn,banilo,2016-02-29 13:12:30,"can be simplified to `fig = plt.figure(figsize=(12, 12))`
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(186, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",simplifi
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 15:44:03,"Was just how the original code was. No problem to change
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",wa origin code No problem chang
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 15:49:40,"Didn't work for me. We need to get the figure object after it was created by plot_stat_map, giving it directly to it in the right size does not scale the colorbar correctly with the image.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(186, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",didnt work We need get figur object creat plotstatmap give directli right size scale colorbar correctli imag
pull_request_commit_comment,1028,nilearn,nilearn,eickenberg,2016-02-29 15:51:55,"this looks a little shocking until you realize that `X` is the fMRI, not the design. It's fine if you follow the script properly. The other option would have been to name it `Y` and the pixels `X` to indicate the encoding direction `X --> Y`.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",look littl shock realiz fmri design it fine follow script properli the option would name pixel indic encod direct
pull_request_commit_comment,1028,nilearn,nilearn,eickenberg,2016-02-29 15:53:09,"Isn't it awesome that we have non-aggregated `r2_score` values accessible in sklearn? ;)
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",isnt awesom nonaggreg valu access sklearn
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 16:08:24,"> this looks a little shocking until you realize that X is the fMRI, not the
> design. It's fine if you follow the script properly. The other option would
> have been to name it Y and the pixels X to indicate the encoding direction X
> --> Y.

Yes, actually. We could call them 'fmri_data', and 'stimuli'.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",ye actual We could call fmridata stimuli
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 16:11:44,"Makes sense. Right now it mimicks the preprocessing/data-loading of the reconstruction example, so you could see that it really just reverses X and y, but giving them expressive names would be much clearer.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",make sens right mimick preprocessingdataload reconstruct exampl could see realli revers X give express name would much clearer
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 18:27:15,"Works now also on CircleCI. As @AlexandreAbraham pointed out, marker_color needed to be set, apparently it was being overridden by edgecolor/facecolor on my computer. Maybe different behavior in diff. matplotlib-versions.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",work also circleci As alexandreabraham point markercolor need set appar overridden edgecolorfacecolor comput mayb differ behavior diff matplotlibvers
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 19:37:41,"> Works now also on CircleCI. As @AlexandreAbraham pointed out, marker_color
> needed to be set, apparently it was being overridden by edgecolor/facecolor on
> my computer.

Awesome! Great job to both of you!
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(174, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",awesom great job
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 19:40:27,"One (last?) question: why are you using new_img_like, and not just the output of masker.inverse_transform(cut_score)?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",one last question use newimglik output maskerinversetransformcutscor
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 19:49:33,"The mask doesn't have the affine transform of the background image.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",the mask doesnt affin transform background imag
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 19:53:10,"> The mask doesn't have the affine transform of the background image.

Hum... One of the two must be wrong, then. Don't you think? I can't
really see another explaination.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",hum one two must wrong dont think I cant realli see anoth explain
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-02-29 19:56:42,"Actually, the mask's affine transform is just an identity matrix.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",actual mask affin transform ident matrix
pull_request_commit_comment,1028,nilearn,nilearn,GaelVaroquaux,2016-02-29 20:00:53,"> Actually, the mask's affine transform is just an identity matrix.

So it's wrong. We must fix it.

@AlexandreAbraham, any chance that you can grab the affine from the
background image and upload to nitrc a fixed version of the mask?
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",So wrong We must fix alexandreabraham chanc grab affin background imag upload nitrc fix version mask
pull_request_commit_comment,1028,nilearn,nilearn,AlexandreAbraham,2016-03-02 09:24:02,"On it.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",On
pull_request_commit_comment,1028,nilearn,nilearn,AlexandreAbraham,2016-03-02 09:57:58,"Done in PR #1038. Note that, unfortunately, you will have to erase manually your miyawaki2008 folder to force downloading.
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",done PR 1038 note unfortun eras manual miyawaki2008 folder forc download
pull_request_commit_comment,1028,nilearn,nilearn,mjboos,2016-03-02 17:33:34,"Great, thank you!
",463dc2ab4d17fd7456b7677a1638237be075bc0e,"(None, '', u'examples/02_decoding/plot_miyawaki_encoding.py')",great thank
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-27 12:05:07,"Encoding example using the Miyawaki et al., 2008 dataset",4df8a7f8070e08c81d381da66496910ca4627645,,encod exampl use miyawaki et al 2008 dataset
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-27 12:09:48,Encoding example for Miyawaki dataset,2fb9da183a1eb58a8f49cae70e89df420fe60a78,,encod exampl miyawaki dataset
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-27 22:05:24,"Added plots of the stimuli, changed description and fixed pep8 violations",59442085239832e1e622d1ff390746666391c572,,ad plot stimuli chang descript fix pep8 violat
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-27 22:30:52,deleted symmetric cbar,d23cc93caf86845069055102a4080974ebc15fe5,,delet symmetr cbar
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-28 00:08:45,rephrased description and comments,a383ede0b04d941b1b119be6c8e96dfa449da475,,rephras descript comment
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-28 17:57:25,integrated comments,f9235a5b68b324eb93bfceefc68ab01529706c4e,,integr comment
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-29 15:42:24,"Slight rephrasing, added marker_color argument",07a4c40ad2d9500d10d0392896ef026eb453fc37,,slight rephras ad markercolor argument
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-02-29 16:32:39,changed variable names,3440fbfd920ca88492f35086820dcd6913bf36a7,,chang variabl name
pull_request_commit,1028,nilearn,nilearn,mjboos,2016-03-02 18:39:45,using affine transform of mask,463dc2ab4d17fd7456b7677a1638237be075bc0e,,use affin transform mask
