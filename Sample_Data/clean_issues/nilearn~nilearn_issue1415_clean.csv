rectype,issueid,project_owner,project_name,actor,time,text,action,title,clean_text
rectype,issueid,project_owner,project_name,actor,time,text,action,title,text
issue_title,1415,nilearn,nilearn,banilo,2017-03-17 14:21:20,"I am using nilearn 0.2.5 and tried to apply a conventional grey matter mask on ~500 VBM images from the HCP dataset. Unfortunately, the NiftiMaskers still do not seem to scale to this size of datasets. Running the following line (vbm_files containing paths to the structural images from the HCP500 release) did not finish on my MacBook Pro with 16GB working memory after 3 hours (no other Python or other big processes running at the same time):

``` python
%timeit -n1 -r1 FS = masker.transform(vbm_files)
```

Perhaps an internal batching approach could be thinkable. When I perform the transform() in chunks of say 50 images the transforming operation is rather fast. The big inconvience however is that the confound removal option of the nifti maskers cannot be easily deployed in this way.

Any ideas?",start issue,transform() of NiftMasker family does not seem ready for big-data,I use nilearn 025 tri appli convent grey matter mask 500 vbm imag hcp dataset unfortun niftimask still seem scale size dataset run follow line vbmfile contain path structur imag hcp500 releas finish macbook pro 16gb work memori 3 hour python big process run time perhap intern batch approach could thinkabl when I perform transform chunk say 50 imag transform oper rather fast the big inconvi howev confound remov option nifti masker cannot easili deploy way ani idea
issue_closed,1415,nilearn,nilearn,GaelVaroquaux,2017-11-06 20:43:24,,closed issue,transform() of NiftMasker family does not seem ready for big-data,
issue_comment,1415,nilearn,nilearn,GaelVaroquaux,2017-03-21 12:52:22,"> I tried again with the MultiNiftiMasker. It also took >1 hour to transform 500 VBM images.

Are you sure that you are not resampling? For instance by specifying a
mask that is on a different grid than the the data. If that's the case,
it's not surprising that it is taking time. Resampling is a costly
operation. If that's not the case, than please profile the run, so that
we understand what's going on, for instance using ""%run -p"".


",,,are sure resampl for instanc specifi mask differ grid data If that case surpris take time resampl costli oper If that case pleas profil run understand what go instanc use run p
issue_comment,1415,nilearn,nilearn,GaelVaroquaux,2017-03-29 13:23:09,"> As such, the explanation based on a costly resampling procedure is not likely.

Then profile.
",,,then profil
issue_comment,1415,nilearn,nilearn,GaelVaroquaux,2017-11-06 20:43:24,"I am closing this issue: it's not helpful. It's a general comment, and not something that someone (eg an external person to the project) can tackle.",,,I close issu help it gener comment someth someon eg extern person project tackl
issue_comment,1415,nilearn,nilearn,AlexandreAbraham,2017-03-17 15:34:39,"To complete Kamalaker's answer: if you use NiftiMasker, data will be concatenated and masked, precisely to be able to run confound removal. The concatenation of your 500 VBM images takes time and memory. With the MultiNiftiMasker, your input will be treated as a list so the images will be loaded one by one.

What worries me is that somebody that has been around nilearn's dev team does not know that. That means that our external users may do the same mistake. Is there a reasonable way to warn users when the input seems fishy in the NiftiMasker?",,,To complet kamalak answer use niftimask data concaten mask precis abl run confound remov the concaten 500 vbm imag take time memori with multiniftimask input treat list imag load one one what worri somebodi around nilearn dev team know that mean extern user may mistak Is reason way warn user input seem fishi niftimask
issue_comment,1415,nilearn,nilearn,banilo,2017-03-21 12:02:44,"I tried again with the ```MultiNiftiMasker```. It also took >1 hour to transform 500 VBM images.

Plus, gathering the whole data internally to be able to run confound removal is by itself not in conflict with internally using a loop over batches. This may prevent memory peaks and the batches can still be concatenated for ```signal.clean()```.",,,I tri It also took plu gather whole data intern abl run confound remov conflict intern use loop batch thi may prevent memori peak batch still concaten
issue_comment,1415,nilearn,nilearn,banilo,2017-03-29 13:21:48,"> Are you sure that you are not resampling?

As I said above (""When I perform the transform() in chunks of say 50 images the transforming operation is rather fast.""), it is considerably faster if I do the same transform() on the same images in batches. As such, the explanation based on a costly resampling procedure is not likely.",,,As I said when I perform transform chunk say 50 imag transform oper rather fast consider faster I transform imag batch As explan base costli resampl procedur like
issue_comment,1415,nilearn,nilearn,mrahim,2017-03-17 14:30:53,Already said in #1281 ,,,alreadi said 1281
issue_comment,1415,nilearn,nilearn,MartinPerez,2017-03-21 12:49:41,"I will join this discussion because its relevant to Nistats. I was wondering why the masker was consuming so much memory when processing all runs. Actually for a moment @bthirion was using MultiNiftiMasker in some parts instead of NiftiMasker. This different way to handle memory did not come up in our discussion when deciding the default masker to use everywhere. In Nistats we do not really use any confound removal, so its better to avoid the concatenation, I also think this is not clear from the documentation. ",,,I join discuss relev nistat I wonder masker consum much memori process run actual moment bthirion use multiniftimask part instead niftimask thi differ way handl memori come discuss decid default masker use everywher In nistat realli use confound remov better avoid concaten I also think clear document
issue_comment,1415,nilearn,nilearn,KamalakerDadi,2017-03-17 14:35:38,Have you tried MultiNiftiMasker ? It can be scalable in your big size case.,,,have tri multiniftimask It scalabl big size case
issue_comment,1415,nilearn,nilearn,bthirion,2017-03-17 21:41:40,If I'm not mistaken only one example uses it. This is not enough.,,,If Im mistaken one exampl use thi enough
