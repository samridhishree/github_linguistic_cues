rectype,issueid,project_owner,project_name,actor,time,text,action,title,clean_text,Test
rectype,issueid,project_owner,project_name,actor,time,text,action,title,text,N
issue_title,154,aio-libs,aioredis,argaen,2016-09-30 14:36:45,"Hi, I'm receiving multiple messages stating the following:

``` python
Task was destroyed but it is pending!
task: <Task pending coro=<RedisPool._do_close() running at /Users/manuelmiranda/.virtualenvs/redis-cache/lib/python3.5/site-packages/aioredis/pool.py:102> wait_for=<Future pending cb=[Task._wakeup()]>>
Task was destroyed but it is pending!
task: <Task pending coro=<RedisConnection._read_data() running at /Users/manuelmiranda/.virtualenvs/redis-cache/lib/python3.5/site-packages/aioredis/connection.py:131> wait_for=<Future pending cb=[Task._wakeup()]> cb=[Future.set_result()]>
Task was destroyed but it is pending!
```

The code I'm using:

``` python
    async def _connect(self):
        if self._pool is None:
            self._pool = await aioredis.create_pool(
                (self.endpoint, self.port))

        return await self._pool

    async def get(self, key):
        with await self._connect() as client:
                await client.get(key)
```

Am I missing something? Isn't the context_manager supposed to close the pool when exits?

Thanks!
",start issue,Task was destroyed but is is pending,Hi Im receiv multipl messag state follow the code Im use Am I miss someth isnt contextmanag suppos close pool exit thank,N
issue_closed,154,aio-libs,aioredis,argaen,2016-10-05 13:20:05,nan,closed issue,Task was destroyed but is is pending,nan,N
issue_comment,154,aio-libs,aioredis,popravich,2016-09-30 15:53:28,"Hi,
Try the following

``` python
async def _connect(self):
    if self._pool is None:
        self._pool = await aioredis.create_pool(
            (self.endpoint, self.port))
    return self._pool  # here no await needed

async def get(self, key):
    async with await self._connect() as client:  # use 'async with'
        await client.get(key)
```
",nan,nan,Hi tri follow,N
issue_comment,154,aio-libs,aioredis,argaen,2016-09-30 16:26:41,"Thanks for the quick response! With the changes it gives the following error:

``` python
>       async with await self._connect() as client:
E       AttributeError: __aexit__
```
",nan,nan,thank quick respons with chang give follow error,N
issue_comment,154,aio-libs,aioredis,popravich,2016-09-30 20:18:53,"try without `async with`, just `with`
",nan,nan,tri without,N
issue_comment,154,aio-libs,aioredis,argaen,2016-10-01 14:03:59,"Not working:

``` python
aiocache/redis.py:50: in set
    with await self._connect() as redis:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <aioredis.pool.RedisPool object at 0x7f4a452acf60>

    def __enter__(self):
        raise RuntimeError(
>           ""'yield from' should be used as a context manager expression"")
E       RuntimeError: 'yield from' should be used as a context manager expression

../../.virtualenvs/aiocache/lib/python3.5/site-packages/aioredis/pool.py:256: RuntimeError
```

The only way I've been able to make it work is with the first version I posted in the first message
",nan,nan,not work the way ive abl make work first version I post first messag,N
issue_comment,154,aio-libs,aioredis,popravich,2016-10-03 07:17:35,"``` python
async def _connect(self):
    if self._pool is None:
        self._pool = await aioredis.create_pool(
            (self.endpoint, self.port))
    return self._pool  # here no await needed

async def get(self, key):
    async with (await self._connect()).get() as client:  # use 'async with'
        await client.get(key)
```

this works for me
",nan,nan,work,N
issue_comment,154,aio-libs,aioredis,argaen,2016-10-03 21:25:04,"Yeah, and it does for me too. Also the first code I posted does. I opened this because for every operation this message seems to appear so it seems something is not being completed or closed correctly. With the code you posted it also happens (I adapted it to run it from a main):

``` python
import aioredis
import asyncio

async def _connect():
    _pool = await aioredis.create_pool(
        (""127.0.0.1"", 6379))
    return _pool

async def get(key):
    async with (await _connect()).get() as client:  # use 'async with'
        await client.get(key)


if __name__ == ""__main__"":
    loop = asyncio.get_event_loop()
    loop.run_until_complete(get(""key""))
```

This shows the following in the output:

``` python
23:24 $ python main.py 
None
Task was destroyed but it is pending!
task: <Task pending coro=<RedisPool._do_close() done, defined at /home/blck/.virtualenvs/aiocache/lib/python3.5/site-packages/aioredis/pool.py:100> wait_for=<Future pending cb=[Task._wakeup()]>>
Task was destroyed but it is pending!
task: <Task pending coro=<RedisConnection._read_data() running at /home/blck/.virtualenvs/aiocache/lib/python3.5/site-packages/aioredis/connection.py:131> wait_for=<Future pending cb=[Task._wakeup()]> cb=[Future.set_result()]>
```
",nan,nan,yeah also first code I post I open everi oper messag seem appear seem someth complet close correctli with code post also happen I adapt run main thi show follow output,N
issue_comment,154,aio-libs,aioredis,popravich,2016-10-04 07:45:15,"This is expected behavior as `pool.close() / await pool.wait_closed()` never gets called.
Connections starts ""background"" task to read data from socket and it runs forever,
`pool.close()` / `await pool.wait_closed()` stops that task and wait it all finishes correctly.
",nan,nan,thi expect behavior never get call connect start background task read data socket run forev stop task wait finish correctli,N
issue_comment,154,aio-libs,aioredis,argaen,2016-10-04 22:08:14,"Ummm interesting. And shouldn't the pool be closed with the `exit` of the context manager? I'm trying to solve this because it's printing this for each test and would like to keep it clean. I've tried to close the pool in the closing of the pytest fixture but not working either. Can you have a look at https://github.com/argaen/aiocache/blob/master/tests/test_redis.py#L39 and let me know if I'm doing something wrong??

The code implementing the connect call is at https://github.com/argaen/aiocache/blob/master/aiocache/backends/redis.py#L94

Thanks a lot for your time :)
",nan,nan,ummm interest and shouldnt pool close context manag Im tri solv print test would like keep clean ive tri close pool close pytest fixtur work either can look let know Im someth wrong the code implement connect call thank lot time,Y
issue_comment,154,aio-libs,aioredis,popravich,2016-10-05 09:43:15,"No problem)

> And shouldn't the pool be closed with the exit of the context manager?

No this will result in new establishing new connection to redis for every `get/multi_get/set/etc`.
So this would be very inefficient and add latency.
Closing pool should be done at the end of program.

`test_redis.py`: should not `redis_cache` fixture be a `yield_fixture`? maybe that is a problem...
You can check aioredis test fixtures.

To make redis closable backend should be instantiated and used explicitly so that one could call
`backend.close()` or `backend._pool.close()`:

``` python
def main(loop):
    redis_backend = config_default_backend(...)
    try:
        loop.run_until_complete(run_main_program())
    finally:
        redis_backend._pool.close()
        loop.run_until_complete(redis_backend._pool.wait_closed())
```
",nan,nan,No problem No result new establish new connect redi everi So would ineffici add latenc close pool done end program fixtur mayb problem you check aioredi test fixtur To make redi closabl backend instanti use explicitli one could call,Y
issue_comment,154,aio-libs,aioredis,argaen,2016-10-05 13:19:46,"> test_redis.py: should not redis_cache fixture be a yield_fixture? maybe that is a problem...
> You can check aioredis test fixtures.

Nope, in pytest 3.0 if a fixture has a `yield` it implicitly becomes an ""old"" yield_fixture. It works out of the box now.

D'oh! I thought `close()` and `wait_closed()` were just the sync and async ways to close the redis connection respectively, my bad. After transforming the fixture to:

``` python
@pytest.fixture
def redis_cache(event_loop, mocker):
    cache = RedisCache(namespace=""test"", loop=event_loop)
    yield cache
    event_loop.run_until_complete(cache.delete(KEY))
    event_loop.run_until_complete(cache.delete(""random""))
    cache._pool.close()
    event_loop.run_until_complete(cache._pool.wait_closed())
```

works perfectly. Thanks a lot for the help!
",nan,nan,nope pytest 30 fixtur implicitli becom old yieldfixtur It work box doh I thought sync async way close redi connect respect bad after transform fixtur work perfectli thank lot help,N
